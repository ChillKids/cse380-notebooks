{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Generating Permutations and Combinations\n",
    "## Divide Pair Conquer\n",
    "### Due: Monday, 1 February 2021, 11:59pm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many occasions when you need to *generate* the permutations or\n",
    "combinations of a set, not just count them.\n",
    "\n",
    "There are many algorithms for generating permutations and combinations --- you\n",
    "can find them if you look.\n",
    "\n",
    "For an application, from a biographical sketch about Donald Knuth by Kenneth\n",
    "Rosen, we learn that\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"Knuth grew up in Milwaukee, where his father taught bookkeeping at a Lutheran\n",
    "high school and owned a small printing business. He was an excellent student,\n",
    "earning academic achievement awards. He applied his intelligence in\n",
    "unconventional ways, winning a contest when he was in the eighth grade by\n",
    "finding as many words as possible that could be formed from the letters in\n",
    "\n",
    "---\n",
    "\n",
    "> **Ziegler's Giant Bar**.\n",
    "\n",
    "___\n",
    "\n",
    "> This won a television set for his school and a candy bar for everyone in his class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knuth found over 4500 words. How many can **you** find?"
   ]
  },
  {
   "source": [
    "In this problem, we will be using combination. Cause look and look are the same words. Stupid me was thinking multiprocessing can fix every problem in the world. Recommanded running this with a .py file. I ended finding 207 in the en_US dictionary. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['z', 'i', 'e', 'g', 'l', 'e', 'r', 's', 'g', 'i', 'a', 'n', 't', 'b', 'a', 'r', 'zi', 'ze', 'zg', 'zl', 'ze', 'zr', 'zs', 'zg', 'zi', 'za', 'zn', 'zt', 'zb', 'za', 'zr', 'ie', 'ig', 'il', 'ie', 'ir', 'is', 'ig', 'ii', 'ia', 'in', 'it', 'ib', 'ia', 'ir', 'eg', 'el', 'ee', 'er', 'es', 'eg', 'ei', 'ea', 'en', 'et', 'eb', 'ea', 'er', 'gl', 'ge', 'gr', 'gs', 'gg', 'gi', 'ga', 'gn', 'gt', 'gb', 'ga', 'gr', 'le', 'lr', 'ls', 'lg', 'li', 'la', 'ln', 'lt', 'lb', 'la', 'lr', 'er', 'es', 'eg', 'ei', 'ea', 'en', 'et', 'eb', 'ea', 'er', 'rs', 'rg', 'ri', 'ra', 'rn', 'rt', 'rb', 'ra', 'rr', 'sg', 'si', 'sa', 'sn', 'st', 'sb', 'sa', 'sr', 'gi', 'ga', 'gn', 'gt', 'gb', 'ga', 'gr', 'ia', 'in', 'it', 'ib', 'ia', 'ir', 'an', 'at', 'ab', 'aa', 'ar', 'nt', 'nb', 'na', 'nr', 'tb', 'ta', 'tr', 'ba', 'br', 'ar']\nhi\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from functools import reduce, partial\n",
    "import enchant\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "dicts = [\"en_BW\", \"en_AU\", \"en_BZ\", \"en_GB\", \"en_JM\", \"en_DK\", \"en_HK\", \"en_GH\", \"en_US\", \"en_ZA\", \"en_ZW\", \"en_SG\", \"en_NZ\", \"en_BS\", \"en_AG\", \"en_PH\", \"en_IE\", \"en_NA\", \"en_TT\", \"en_IN\", \"en_NG\", \"en_CA\"]\n",
    "\n",
    "us = enchant.Dict(\"en_AU\")\n",
    "\n",
    "def split(word): \n",
    "    return list(word) \n",
    "\n",
    "def check(y, l):\n",
    "    return enchant.Dict(l).check(y)\n",
    "\n",
    "def checkwords(lang, n):\n",
    "    print(lang + \" Starting: \")\n",
    "    all_comb = [*filter(partial(check, l = lang) , n)]\n",
    "    comb = [x for x in n if x not in all_comb]\n",
    "    print(lang + \" - \" + str(len(all_comb)) + \", \" + str(len(comb)))\n",
    "    return all_comb\n",
    "      \n",
    "# Driver code \n",
    "if __name__ == '__main__':\n",
    "    word = \"zieglersgiantbar\"\n",
    "    comb = []\n",
    "    for i in range(1, 18):\n",
    "        comb.append([*combinations(split(word), i )])\n",
    "\n",
    "    comb = [*map(lambda x : [*map(lambda y: ' '.join(y).replace(\" \", \"\"), x)], comb)]\n",
    "    #    all_comb = reduce(lambda x, y: x + y, [x for x in [*map (lambda x : [*filter(check , x)], [*map(lambda x : [*map(lambda y: ' '.join(y).replace(\" \", \"\"), x)], comb)])] if x])\n",
    "    comb = reduce(lambda x, y: x + y, [x for x in comb if x])\n",
    "\n",
    "    with mp.Pool(16) as p:\n",
    "        words = p.map(partial(checkwords, n = comb), dicts)\n",
    "\n",
    "    words = reduce(lambda x, y: x + y, [x for x in words if x])\n",
    "    print(\"Total: \" + str(len(list(set(words))))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fc0940015f1a213f94692d1bb0f6f94a406415fa94d32b2f3f9e51375e35b42e"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}